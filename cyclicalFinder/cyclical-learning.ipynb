{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from pyimagesearch.minigooglenet import MiniGoogLeNet\n",
    "from pyimagesearch.clr_callback import CyclicLR\n",
    "from pyimagesearch import config\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "# from tensorflow.keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_witdth, img_height = 32, 32\n",
    "\n",
    "\n",
    "# load the training and testing data, converting the images from\n",
    "# integers to floats\n",
    "print(\"[INFO] loading Fashion MNIST data...\")\n",
    "\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    "# ((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype(\"float\")\n",
    "testX = testX.astype(\"float\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply mean subtraction to the data\n",
    "mean = np.mean(trainX, axis=0)\n",
    "trainX -= mean\n",
    "testX -= mean\n",
    "\n",
    "# Fashion MNIST images are 28x28 but the network we will be training\n",
    "# is expecting 32x32 images\n",
    "trainX = np.array([cv2.resize(x, (img_witdth, img_height)) for x in trainX])\n",
    "testX = np.array([cv2.resize(x, (img_witdth, img_height)) for x in testX])\n",
    "\n",
    "# scale the pixel intensities to the range [0, 1]\n",
    "trainX = trainX.astype(\"float\") / 255.0\n",
    "testX = testX.astype(\"float\") / 255.0\n",
    "\n",
    "\n",
    "# reshape the data matrices to include a channel dimension (required\n",
    "# for training)\n",
    "\n",
    "trainX = trainX.reshape((trainX.shape[0], img_witdth, img_height, 1))\n",
    "testX = testX.reshape((testX.shape[0], img_witdth, img_height, 1))\n",
    "\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=config.MIN_LR, momentum=0.9)\n",
    "model = MiniGoogLeNet.build(width=img_witdth, height=img_height, depth=1, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the cyclical learning rate callback\n",
    "print(\"[INFO] using '{}' method\".format(config.CLR_METHOD))\n",
    "clr = CyclicLR(\n",
    "    mode=config.CLR_METHOD,\n",
    "    base_lr=config.MIN_LR,\n",
    "    max_lr=config.MAX_LR,\n",
    "    step_size=config.STEP_SIZE * (trainX.shape[0] // config.BATCH_SIZE),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(\n",
    "    x=aug.flow(trainX, trainY, batch_size=config.BATCH_SIZE),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=trainX.shape[0] // config.BATCH_SIZE,\n",
    "    epochs=config.NUM_EPOCHS,\n",
    "    callbacks=[clr],\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the learning rate finder and then train with learning\n",
    "# rates ranging from 1e-10 to 1e+1\n",
    "print(\"[INFO] finding learning rate...\")\n",
    "lrf = LearningRateFinder(model)\n",
    "lrf.find(\n",
    "    aug.flow(trainX, trainY, batch_size=config.BATCH_SIZE),\n",
    "    1e-10,\n",
    "    1e1,\n",
    "    stepsPerEpoch=np.ceil((len(trainX) / float(config.BATCH_SIZE))),\n",
    "    batchSize=config.BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss for the various learning rates and save the\n",
    "# resulting plot to disk\n",
    "lrf.plot_loss()\n",
    "plt.savefig(config.LRFIND_PLOT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
